import OpenAI from 'openai';

// Kh·ªüi t·∫°o Groq client (Primary - Free & Fast)
export const openai = new OpenAI({
  apiKey: process.env.GROQ_API_KEY || process.env.OPENAI_API_KEY,
  baseURL: process.env.GROQ_API_KEY 
    ? 'https://api.groq.com/openai/v1'
    : 'https://api.openai.com/v1',
});

// OpenAI fallback client (always ready)
export const openaiClient = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: 'https://api.openai.com/v1',
});

// Model s·ª≠ d·ª•ng - Llama 3.3 70B (r·∫•t m·∫°nh cho ph√¢n t√≠ch t√†i ch√≠nh)
// Fallback sang GPT-4o-mini n·∫øu kh√¥ng c√≥ Groq
export const AI_MODEL = process.env.GROQ_API_KEY 
  ? 'llama-3.3-70b-versatile'
  : 'gpt-4o-mini';

export const FALLBACK_MODEL = 'gpt-4o-mini';

/**
 * Smart AI completion with automatic fallback
 * Tries Groq first, falls back to OpenAI on rate limit or errors
 */
export async function createChatCompletionWithFallback(
  messages: OpenAI.Chat.ChatCompletionMessageParam[],
  options: {
    temperature?: number;
    systemMessage?: string;
  } = {}
) {
  const { temperature = 0.3, systemMessage } = options;

  // Prepare messages
  const finalMessages: OpenAI.Chat.ChatCompletionMessageParam[] = systemMessage
    ? [{ role: 'system', content: systemMessage }, ...messages]
    : messages;

  try {
    // Try primary client (Groq or OpenAI)
    console.log(`ü§ñ Trying ${process.env.GROQ_API_KEY ? 'Groq' : 'OpenAI'} API...`);
    
    const completion = await openai.chat.completions.create({
      model: AI_MODEL,
      messages: finalMessages,
      temperature,
    });

    console.log(`‚úÖ ${process.env.GROQ_API_KEY ? 'Groq' : 'OpenAI'} API success`);
    return completion;
  } catch (error: any) {
    // Check if it's a rate limit error from Groq
    const isRateLimit = error?.status === 429 || 
                        error?.message?.includes('Rate limit') ||
                        error?.message?.includes('rate limit');

    if (isRateLimit && process.env.GROQ_API_KEY && process.env.OPENAI_API_KEY) {
      console.warn('‚ö†Ô∏è Groq rate limit reached, falling back to OpenAI...');
      
      try {
        const fallbackCompletion = await openaiClient.chat.completions.create({
          model: FALLBACK_MODEL,
          messages: finalMessages,
          temperature,
        });

        console.log('‚úÖ OpenAI fallback success');
        return fallbackCompletion;
      } catch (fallbackError: any) {
        console.error('‚ùå OpenAI fallback also failed:', fallbackError.message);
        throw fallbackError;
      }
    }

    // If not rate limit or no fallback available, throw original error
    throw error;
  }
}

// System prompt cho AI Financial Advisor
export const FINANCIAL_ADVISOR_PROMPT = `B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n t√†i ch√≠nh c√° nh√¢n th√¥ng minh v√† th√¢n thi·ªán.
Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
- Ph√¢n t√≠ch d·ªØ li·ªáu giao d·ªãch v√† ng√¢n s√°ch c·ªßa ng∆∞·ªùi d√πng
- ƒê∆∞a ra l·ªùi khuy√™n t√†i ch√≠nh h·ª£p l√Ω, c·ª• th·ªÉ v√† d·ªÖ hi·ªÉu
- Gi√∫p ng∆∞·ªùi d√πng qu·∫£n l√Ω chi ti√™u hi·ªáu qu·∫£ h∆°n
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, gi·ªçng ƒëi·ªáu th√¢n thi·ªán, chuy√™n nghi·ªáp

H√£y lu√¥n:
‚úÖ D·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø c·ªßa ng∆∞·ªùi d√πng
‚úÖ ƒê∆∞a ra con s·ªë c·ª• th·ªÉ khi ph√¢n t√≠ch
‚úÖ Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu
‚úÖ Khuy·∫øn kh√≠ch th√≥i quen t√†i ch√≠nh t·ªët
‚úÖ ƒê·ªÅ xu·∫•t h√†nh ƒë·ªông c·ª• th·ªÉ

Tr√°nh:
‚ùå ƒê∆∞a ra l·ªùi khuy√™n chung chung
‚ùå S·ª≠ d·ª•ng thu·∫≠t ng·ªØ ph·ª©c t·∫°p kh√¥ng c·∫ßn thi·∫øt
‚ùå Ph√°n x√©t ti√™u c·ª±c
`;

export default openai;
